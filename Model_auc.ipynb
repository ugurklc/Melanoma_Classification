{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIIM-ISIC Melanoma Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify melanoma in lesion images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from shutil import copyfile, rmtree, move\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D\n",
    "from functools import partial\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original \"jpeg\" files were stored in train and validation sub-categories. In the original jpeg files, the \"melignant\" and \"benign\" labels were not indicated, instead, they were labelled in the \"train.csv\" file.\n",
    "\n",
    "So, in order to use keras.preprocessing.ImageDataGenerator, all the jpeg files were identified as \"melignant\" and \"bening\" first, and then split into train and validation set with the split ratio of 0.8.\n",
    "\n",
    "Below codes show the total numbers of instances. Note that, all the were mixed first and then splitted into train test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the paths to the directories\n",
    "source_path = '/sfs/lustre/bahamut/scratch/uk7ud/Kaggle Melanoma/source'\n",
    "source_benign_path = os.path.join(source_path, 'benign')\n",
    "source_melignant_path = os.path.join(source_path, 'melignant')\n",
    "data_path = '/sfs/lustre/bahamut/scratch/uk7ud/Kaggle Melanoma/data'\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "train_benign_path = os.path.join(train_path, 'benign')\n",
    "train_melignant_path = os.path.join(train_path, 'melignant')\n",
    "validation_path = os.path.join(data_path, 'validation')\n",
    "validation_benign_path = os.path.join(validation_path, 'benign')\n",
    "validation_melignant_path = os.path.join(validation_path, 'melignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_source_benign = len(os.listdir(source_benign_path))\n",
    "len_source_melignant = len(os.listdir(source_melignant_path))\n",
    "len_source_total = len_source_benign + len_source_melignant\n",
    "source_melignant_benign_ratio =  len_source_melignant/len_source_benign\n",
    "\n",
    "len_train_benign = len(os.listdir(train_benign_path))\n",
    "len_train_melignant = len(os.listdir(train_melignant_path))\n",
    "len_train_total = len_train_benign + len_train_melignant\n",
    "train_melignant_benign_ratio =  len_train_melignant/len_train_benign\n",
    "\n",
    "len_validation_benign = len(os.listdir(validation_benign_path))\n",
    "len_validation_melignant = len(os.listdir(validation_melignant_path))\n",
    "len_validation_total = len_validation_benign + len_validation_melignant\n",
    "validation_melignant_benign_ratio =  len_validation_melignant/len_validation_benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at above numbers, we are in a good spot to start training. Keep in mind that the data is highly skewed and thats why we will use ROC AUC for performance of the model.\n",
    "\n",
    "The melignant/benign ratio is also important for data separation. The original data has a split ratio of 0.018 and we kept that ratio while spliting our data into train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Source Benign: 32542\n",
      "Total Source Melignant: 584\n",
      "Source Total: 33126\n",
      "Source Melignant/Benign: 0.017946038965029807\n",
      "\n",
      "Total Train Benign: 26033\n",
      "Total Train Melignant: 467\n",
      "Train Total: 26500\n",
      "Train Melignant/Benign: 0.01793877002266354\n",
      "\n",
      "Total Validation Benign: 6509\n",
      "Total Validation Melignant: 117\n",
      "Validation Total: 6626\n",
      "Validation Melignant/Benign: 0.01797511138423721\n"
     ]
    }
   ],
   "source": [
    "print('Total Source Benign:', len_source_benign)\n",
    "print('Total Source Melignant:', len_source_melignant)\n",
    "print('Source Total:', len_source_total)\n",
    "print('Source Melignant/Benign:',source_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal Train Benign:', len_train_benign)\n",
    "print('Total Train Melignant:', len_train_melignant)\n",
    "print('Train Total:', len_train_total)\n",
    "print('Train Melignant/Benign:', train_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal Validation Benign:', len_validation_benign)\n",
    "print('Total Validation Melignant:', len_validation_melignant)\n",
    "print('Validation Total:', len_validation_total)\n",
    "print('Validation Melignant/Benign:',validation_melignant_benign_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image shapes may be different in size, so we have to resize all of them in the same size (1500 x 1500 for example). Below code gives the average dimensions of the images. Let's chose \"Source Benign\" directory for this since we have 32542 images in this folder out of 33126."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (200, 200, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26500 images belonging to 2 classes.\n",
      "Found 6626 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data using ImageDataGenerator API from keras and also include data augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    batch_size = 32,\n",
    "    target_size = input_shape[:2],\n",
    "    class_mode = 'binary'\n",
    ") \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    batch_size = 32,\n",
    "    target_size = input_shape[:2],\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 200, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 50, 50, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 21,596,929\n",
      "Trainable params: 21,596,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=3, input_shape=input_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = os.path.join(os.curdir, \"my_logs\", \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_keras_datagen.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 829 steps, validate for 829 steps\n",
      "Epoch 1/200\n",
      "829/829 [==============================] - 15886s 19s/step - loss: 0.6925 - auc: 0.5272 - val_loss: 0.6795 - val_auc: 0.6906\n",
      "Epoch 2/200\n",
      "412/829 [=============>................] - ETA: 51:24 - loss: 0.6724 - auc: 0.5793"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / 32542)*(33126)/2.0 \n",
    "weight_for_1 = (1 / 584)*(33126)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    epochs=200, \n",
    "                    validation_data=train_generator, \n",
    "                    class_weight = class_weight,\n",
    "                    callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow210_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
