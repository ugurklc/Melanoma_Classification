{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from shutil import copyfile, rmtree, move\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '/sfs/lustre/bahamut/scratch/uk7ud/Kaggle Melanoma/source'\n",
    "source_benign_path = os.path.join(source_path, 'benign')\n",
    "source_melignant_path = os.path.join(source_path, 'melignant')\n",
    "data_path = '/sfs/lustre/bahamut/scratch/uk7ud/Kaggle Melanoma/data'\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "train_benign_path = os.path.join(train_path, 'benign')\n",
    "train_melignant_path = os.path.join(train_path, 'melignant')\n",
    "validation_path = os.path.join(data_path, 'validation')\n",
    "validation_benign_path = os.path.join(validation_path, 'benign')\n",
    "validation_melignant_path = os.path.join(validation_path, 'melignant')\n",
    "\n",
    "# Create new directories for small train and validation data\n",
    "s_data_path = '/sfs/lustre/bahamut/scratch/uk7ud/Kaggle Melanoma/s_data'\n",
    "s_train_path = os.path.join(s_data_path, 's_train')\n",
    "s_train_benign_path = os.path.join(s_train_path, 's_benign')\n",
    "s_train_melignant_path = os.path.join(s_train_path, 's_melignant')\n",
    "s_validation_path = os.path.join(s_data_path, 's_validation')\n",
    "s_validation_benign_path = os.path.join(s_validation_path, 's_benign')\n",
    "s_validation_melignant_path = os.path.join(s_validation_path, 's_melignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_source_benign = len(os.listdir(source_benign_path))\n",
    "len_source_melignant = len(os.listdir(source_melignant_path))\n",
    "len_source_total = len_source_benign + len_source_melignant\n",
    "source_melignant_benign_ratio =  len_source_melignant/len_source_benign\n",
    "\n",
    "len_train_benign = len(os.listdir(train_benign_path))\n",
    "len_train_melignant = len(os.listdir(train_melignant_path))\n",
    "len_train_total = len_train_benign + len_train_melignant\n",
    "train_melignant_benign_ratio =  len_train_melignant/len_train_benign\n",
    "\n",
    "len_validation_benign = len(os.listdir(validation_benign_path))\n",
    "len_validation_melignant = len(os.listdir(validation_melignant_path))\n",
    "len_validation_total = len_validation_benign + len_validation_melignant\n",
    "validation_melignant_benign_ratio =  len_validation_melignant/len_validation_benign\n",
    "\n",
    "len_s_train_benign = len(os.listdir(s_train_benign_path))\n",
    "len_s_train_melignant = len(os.listdir(s_train_melignant_path))\n",
    "len_s_train_total = len_train_benign + len_train_melignant\n",
    "train_s_melignant_benign_ratio =  len_s_train_melignant/len_s_train_benign\n",
    "\n",
    "len_s_validation_benign = len(os.listdir(s_validation_benign_path))\n",
    "len_s_validation_melignant = len(os.listdir(s_validation_melignant_path))\n",
    "len_s_validation_total = len_validation_benign + len_validation_melignant\n",
    "validation_s_melignant_benign_ratio =  len_s_validation_melignant/len_s_validation_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Source Benign: 32542\n",
      "Total Source Melignant: 584\n",
      "Source Total: 33126\n",
      "Source Melignant/Benign: 0.017946038965029807\n",
      "\n",
      "Total Train Benign: 26033\n",
      "Total Train Melignant: 467\n",
      "Train Total: 26500\n",
      "Train Melignant/Benign: 0.01793877002266354\n",
      "\n",
      "Total Validation Benign: 6509\n",
      "Total Validation Melignant: 117\n",
      "Validation Total: 6626\n",
      "Validation Melignant/Benign: 0.01797511138423721\n",
      "\n",
      "Total s_Train Benign: 2603\n",
      "Total s_Train Melignant: 46\n",
      "Train s_Total: 26500\n",
      "Train s_Melignant/Benign: 0.017671917018824434\n",
      "\n",
      "Total s_Validation Benign: 651\n",
      "Total s_Validation Melignant: 12\n",
      "Validation s_Total: 6626\n",
      "Validation s_Melignant/Benign: 0.018433179723502304\n"
     ]
    }
   ],
   "source": [
    "print('Total Source Benign:', len_source_benign)\n",
    "print('Total Source Melignant:', len_source_melignant)\n",
    "print('Source Total:', len_source_total)\n",
    "print('Source Melignant/Benign:',source_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal Train Benign:', len_train_benign)\n",
    "print('Total Train Melignant:', len_train_melignant)\n",
    "print('Train Total:', len_train_total)\n",
    "print('Train Melignant/Benign:', train_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal Validation Benign:', len_validation_benign)\n",
    "print('Total Validation Melignant:', len_validation_melignant)\n",
    "print('Validation Total:', len_validation_total)\n",
    "print('Validation Melignant/Benign:',validation_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal s_Train Benign:', len_s_train_benign)\n",
    "print('Total s_Train Melignant:', len_s_train_melignant)\n",
    "print('Train s_Total:', len_s_train_total)\n",
    "print('Train s_Melignant/Benign:', train_s_melignant_benign_ratio)\n",
    "\n",
    "print('\\nTotal s_Validation Benign:', len_s_validation_benign)\n",
    "print('Total s_Validation Melignant:', len_s_validation_melignant)\n",
    "print('Validation s_Total:', len_s_validation_total)\n",
    "print('Validation s_Melignant/Benign:',validation_s_melignant_benign_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_size(source):\n",
    "    \n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    \n",
    "    for item in os.listdir(source):\n",
    "        img = os.path.join(source,item)\n",
    "        img_pixels = imread(img)\n",
    "        d1, d2, colors = img_pixels.shape\n",
    "        dim1.append(d1)\n",
    "        dim2.append(d2)\n",
    "    \n",
    "    avg_dim1 = np.mean(dim1)\n",
    "    avg_dim2 = np.mean(dim2)\n",
    "    image_shape = (avg_dim1,avg_dim2,3)\n",
    "    \n",
    "    return image_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2676.304147465438, 4032.2273425499234, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate_avg_size(s_validation_benign_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2649 images belonging to 2 classes.\n",
      "Found 663 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data using ImageDataGenerator API from keras and also include data augmentation\n",
    "\n",
    "s_train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "s_train_generator = s_train_datagen.flow_from_directory(\n",
    "    s_train_path,\n",
    "    batch_size = 32,\n",
    "    target_size = input_shape[:2],\n",
    "    class_mode = 'binary'\n",
    ") \n",
    "\n",
    "s_validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "s_validation_generator = s_validation_datagen.flow_from_directory(\n",
    "    s_validation_path,\n",
    "    batch_size = 32,\n",
    "    target_size = input_shape[:2],\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 350464)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               44859520  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 45,976,321\n",
      "Trainable params: 45,976,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=3, input_shape=input_shape),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 83 steps, validate for 21 steps\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 525s 6s/step - loss: 0.1167 - auc_1: 0.4584 - val_loss: 0.1072 - val_auc_1: 0.5000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 524s 6s/step - loss: 0.1139 - auc_1: 0.5043 - val_loss: 0.1058 - val_auc_1: 0.4852\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 525s 6s/step - loss: 0.1180 - auc_1: 0.4168 - val_loss: 0.1044 - val_auc_1: 0.4900\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 526s 6s/step - loss: 0.1045 - auc_1: 0.5523 - val_loss: 0.1051 - val_auc_1: 0.5000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 525s 6s/step - loss: 0.1158 - auc_1: 0.4598 - val_loss: 0.1145 - val_auc_1: 0.4977\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 525s 6s/step - loss: 0.1091 - auc_1: 0.4730 - val_loss: 0.0906 - val_auc_1: 0.5008\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 524s 6s/step - loss: 0.1562 - auc_1: 0.4828 - val_loss: 0.0920 - val_auc_1: 0.6640\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 525s 6s/step - loss: 0.1042 - auc_1: 0.5364 - val_loss: 0.0903 - val_auc_1: 0.5038\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 523s 6s/step - loss: 0.1009 - auc_1: 0.5257 - val_loss: 0.0914 - val_auc_1: 0.5038\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 524s 6s/step - loss: 0.1086 - auc_1: 0.4229 - val_loss: 0.0895 - val_auc_1: 0.5046\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 523s 6s/step - loss: 0.0984 - auc_1: 0.5449 - val_loss: 0.0987 - val_auc_1: 0.5054\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 522s 6s/step - loss: 0.1091 - auc_1: 0.4886 - val_loss: 0.0988 - val_auc_1: 0.5000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 523s 6s/step - loss: 0.0998 - auc_1: 0.4983 - val_loss: 0.0930 - val_auc_1: 0.5000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 503s 6s/step - loss: 0.0980 - auc_1: 0.5356 - val_loss: 0.0896 - val_auc_1: 0.5000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 465s 6s/step - loss: 0.1050 - auc_1: 0.4483 - val_loss: 0.1086 - val_auc_1: 0.5000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 466s 6s/step - loss: 0.1021 - auc_1: 0.4524 - val_loss: 0.0901 - val_auc_1: 0.5000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 465s 6s/step - loss: 0.0984 - auc_1: 0.4739 - val_loss: 0.0903 - val_auc_1: 0.5000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 465s 6s/step - loss: 0.0997 - auc_1: 0.4874 - val_loss: 0.0896 - val_auc_1: 0.5000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 465s 6s/step - loss: 0.0960 - auc_1: 0.5339 - val_loss: 0.0896 - val_auc_1: 0.5000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 465s 6s/step - loss: 0.1041 - auc_1: 0.4574 - val_loss: 0.0897 - val_auc_1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(s_train_generator,\n",
    "                    epochs=20,\n",
    "                    validation_data=s_validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow210_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
